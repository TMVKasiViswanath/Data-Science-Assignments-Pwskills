{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059b5e8-bce8-4344-9fba-ba53b27d9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision: Precision is the ratio of correctly predicted positive observations to \n",
    "the total predicted positive observations. It focuses on the accuracy of the positive predictions.\n",
    "A high precision indicates that the model is making fewer false positive predictions.\n",
    "\n",
    "Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "Recall: Recall, also known as sensitivity or true positive rate, is the ratio of correctly predicted\n",
    "positive observations to the all observations in actual class. It focuses on how many of the actual \n",
    "positives were captured by the model. A high recall indicates that the model is able to correctly \n",
    "identify most of the positive cases.\n",
    "\n",
    "Recall = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "While precision and recall are both important, they can be in conflict with each other. For example, \n",
    "if a model predicts all instances as positive, it may achieve high recall but the precision will be \n",
    "low because many of the predictions are false positives. Conversely, if the model predicts only a few\n",
    "instances as positive, it may achieve high precision but the recall will be low because many of the \n",
    "actual positives are missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3edc415-f998-4b95-aa6a-405495f58adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "The F1 score is a metric that combines both precision and recall into a single value. It is the harmonic\n",
    "mean of precision and recall, providing a balance between the two metrics\n",
    "The F1 score ranges from 0 to 1, where a higher value indicates better model performance. It is particularly\n",
    "useful when you want to find an optimal balance between precision and recall, especially in cases where you\n",
    "cannot prioritize one over the other.\n",
    "\n",
    "The main difference between the F1 score and precision/recall is that the F1 score considers both false\n",
    "positives (precision) and false negatives (recall), whereas precision and recall focus only on one aspect\n",
    "each. This makes the F1 score a more comprehensive metric for evaluating the performance of a \n",
    "classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aebb224-3146-4b6c-bd7f-a1e8a7b5672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC Curve: The ROC curve is a graphical representation of the true positive rate (sensitivity) against\n",
    "the false positive rate (1-specificity) for different threshold values. It helps visualize the trade-off\n",
    "between sensitivity and specificity. The diagonal line (the line of no-discrimination) represents the \n",
    "performance of a random classifier, while a curve above this line indicates a better-than-random classifier.\n",
    "\n",
    "\n",
    "AUC: The AUC represents the area under the ROC curve. It provides a single value to summarize the overall\n",
    "performance of the classifier across all possible thresholds. An AUC of 0.5 suggests a random classifier, \n",
    "while an AUC of 1.0 indicates a perfect classifier. Generally, a higher AUC indicates a better model\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb0c260-06aa-4554-976f-6ab2480bc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy: Use accuracy when the classes are balanced and misclassifying both classes is equally important.\n",
    "However, accuracy may not be suitable for imbalanced datasets.\n",
    "\n",
    "Precision and Recall: Use precision when minimizing false positives is important (e.g., spam detection).\n",
    "Use recall when minimizing false negatives is critical (e.g., disease diagnosis).\n",
    "\n",
    "F1 Score: Use the F1 score when you want to balance precision and recall, especially when there is an \n",
    "uneven class distribution.\n",
    "\n",
    "ROC AUC: Use ROC AUC when you want to evaluate the model ability to discriminate between positive and \n",
    "negative classes across various thresholds, especially in imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a394b-a5b9-43fd-8fd7-c00170d9d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "One-vs-Rest (OvR): In this approach, you train a separate binary logistic regression\n",
    "classifier for each class, treating that class as the positive class and all other classes as the negative\n",
    "class. During prediction, you use the classifier that gives the highest probability as the predicted class.\n",
    "\n",
    "Multinomial Logistic Regression: Another approach is to modify the logistic regression algorithm to\n",
    "directly support multiple classes. This is often called multinomial logistic regression or softmax\n",
    "regression. Instead of modeling the probability of one class versus the others \n",
    "(as in binary logistic regression), multinomial logistic regression models the probability of each \n",
    "class independently, and the probabilities sum to one across all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65263bf-73ed-4f86-8359-e25ce23cbdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define the Problem: Decide what you want to predict and why.\n",
    "\n",
    "Get the Data: Collect the data you need for the prediction task.\n",
    "\n",
    "Prepare the Data: Clean the data, handle missing values, and convert it into a format suitable for modeling.\n",
    "\n",
    "Explore the Data: Look at the data to understand its patterns and relationships.\n",
    "\n",
    "Build the Model: Choose a model suitable for your problem (e.g., logistic regression, decision tree) and\n",
    "train it on your data.\n",
    "\n",
    "Evaluate the Model: Test the model on new data to see how well it predicts the outcomes.\n",
    "\n",
    "Deploy the Model: Use the model to make predictions in real-world scenarios.\n",
    "\n",
    "Monitor and Maintain the Model: Regularly check the model performance and update it if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d43038e-f9d2-4873-900e-289bb9054b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model deployment means putting your trained machine learning model into action so it can make predictions\n",
    "in real-world situations. It is important because it allows you to use your model to make informed decisions\n",
    "automate tasks, improve efficiency, scale up, and drive innovation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc30091-bfc7-491b-af72-44fefe02e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Using multi-cloud platforms for model deployment means putting your models on more than one cloud service, \n",
    "like AWS and Azure. This helps because it gives you more options, reduces the risk of problems with one \n",
    "provider, can save money, and makes your models faster and more reliable for people in different places.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e4d12-6c27-4715-bee1-62896ffc6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Benefits:\n",
    "\n",
    "Flexibility: Can choose the best services from different providers.\n",
    "Reliability: Less risk of downtime or data loss.\n",
    "Cost Optimization: Can save money by using different providers.\n",
    "Geographic Reach: Better service for customers in different places.\n",
    "\n",
    "Challenges:\n",
    "\n",
    "Complexity: Managing services from different providers is hard.\n",
    "Data Security: Keeping data safe and following rules is more complicated.\n",
    "Interoperability: Making different services work together can be difficult.\n",
    "Cost Management: Need to watch costs closely to avoid surprises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00476430-876d-49d1-a3de-6ef5baabdd79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
